{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Содержание:\n",
    "\n",
    "    1) Метод tf-idf с классификаторами:\n",
    "            1) Ridge Classifier\n",
    "            2) Perceptron\n",
    "            3) Passive Agressive\n",
    "            4) BeurnolliNB\n",
    "            5) MultinomialNB\n",
    "            6) KNeighbors\n",
    "            7) RandomForest\n",
    "            8) NearestCentroid\n",
    "            9) SGDClassifier\n",
    "            10) LinearSVC\n",
    "    2) Визуализация\n",
    "    3) Метод Hashing с классификаторами:\n",
    "            1) Ridge Classifier\n",
    "            2) Perceptron\n",
    "            3) Passive Agressive\n",
    "            4) BeurnolliNB\n",
    "            5) MultinomialNB\n",
    "            6) KNeighbors\n",
    "            7) RandomForest\n",
    "            8) NearestCentroid\n",
    "            9) SGDClassifier\n",
    "            10) LinearSVC\n",
    "    4) Визуализация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Загружаю данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('./out.csv', 'r')\n",
    "file_hash_all = {}\n",
    "for line in f:\n",
    "    attrs = line.split(';')\n",
    "    path = attrs[0]\n",
    "    class_name = attrs[8]\n",
    "    if ' ' in class_name:\n",
    "        class_name = class_name.split()[0]\n",
    "    if '|' in class_name:\n",
    "        class_name = class_name.split('|')[0]\n",
    "    file_name = os.path.basename(path)\n",
    "    dir_name = os.path.dirname(path)\n",
    "    full_dir = os.path.join('/Users/Valeriya/Desktop/CoursePaper/corpus', dir_name)\n",
    "    files = os.listdir(full_dir)\n",
    "    if file_name in files:\n",
    "        file_hash_all[file_name] = class_name\n",
    "    elif file_name + '.xml' in files:\n",
    "        file_hash_all[file_name + '.xml'] = class_name\n",
    "    elif file_name + '.xhtml' in files:\n",
    "        file_hash_all[file_name + '.xhtml'] = class_name\n",
    "    else:\n",
    "        edit = 1000\n",
    "        true_name = ''\n",
    "        for file_in_dir in files:\n",
    "            dist = distance(file_name, file_in_dir)\n",
    "            if dist < edit:\n",
    "                edit = dist\n",
    "                true_name = file_in_dir\n",
    "        file_hash_all[true_name] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('./out.csv', 'r')\n",
    "# cl = {'отчет':0,'поздравление':0, 'интервью':0, 'репортаж':0, 'хроника':0, 'объявление':0, 'комментарий':0,\n",
    "#       'совет':0, 'анонс':0, 'заметка':0, 'информационное сообщение':0, 'статья':0}\n",
    "cl = {'статья':0, 'комментарий':0, 'интервью':0}\n",
    "# cl = {'отчет':0,'поздравление':0}\n",
    "file_hash = defaultdict(int)\n",
    "file_all = defaultdict(int)\n",
    "for file_name, class_name in file_hash_all.items():\n",
    "    if class_name in cl:\n",
    "        cl[class_name] += 1\n",
    "#         if cl[class_name] <= 150:\n",
    "        file_hash[file_name] = class_name\n",
    "    file_all[class_name] +=1\n",
    "#     elif class_name == 'репортаж' or class_name == 'отчет':\n",
    "#         cl['other'] += 1\n",
    "#         file_hash[file_name] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "q = 0\n",
    "\n",
    "for i in file_all:\n",
    "    q+=1\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "for i in file_all:\n",
    "    t+= file_all[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'': 2575, 'рецензия': 90, 'заявление': 2, 'беседа': 8, 'указ': 7, 'памфлет': 2, 'пресс-конференция': 1, 'тест': 3, 'уведомление': 1, 'репортаж': 331, 'пресс-релиз': 4, 'проповедь': 1, 'буклет': 1, 'отчет': 576, 'комикс': 6, 'резолюция': 1, 'заметка': 3715, 'подпись': 1, 'эссе': 14, 'лекция': 1, 'предисловие': 2, 'поздравление': 198, 'комментарии': 173, 'некролог': 17, 'статья': 2503, 'type': 1, 'обращение': 29, 'закон': 5, 'отзыв': 22, 'публицистика': 7, 'очерк': 108, 'распоряжение': 13, 'инструкция': 17, 'консультация': 3, 'тезисы': 2, 'предисловие,': 2, 'информационное': 1033, 'доклад': 2, 'совет': 121, 'план': 1, 'фельетон': 4, 'подбор': 1, 'постановление': 89, 'речь': 2, 'хроника': 284, 'комментарий': 674, 'обзор': 50, 'биография': 9, 'послание': 1, 'сказка': 1, 'мемуары': 14, 'письмо': 94, 'положение': 8, 'миниатюра': 7, 'объявление': 384, 'правила': 3, 'игра': 8, 'аннотация': 15, 'рассказ': 3, 'анонс': 227, 'гороскоп': 4, 'монография': 1, 'дневник,': 10, 'интервью': 834, 'надпись': 8, 'рецепт': 21, 'календарь': 3, 'анкета': 1, 'решение': 1, 'стихотворение': 21, 'поучение': 1})\n"
     ]
    }
   ],
   "source": [
    "print(file_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            open_name = os.path.join(root, filename)\n",
    "            if filename in file_hash:\n",
    "                class_text = file_hash[filename]\n",
    "                tree = etree.parse(open_name)\n",
    "                yield tree, class_text, open_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def mystem_tokenizer(string):\n",
    "    tokens = m.lemmatize(string)\n",
    "    word_tokens = []\n",
    "    for token in tokens:\n",
    "        # if token.isalnum():\n",
    "        if token.isalpha():\n",
    "            word_tokens.append(token)\n",
    "    return word_tokens\n",
    "    \n",
    "# CountVectorizer(tokenizer=mystem_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/Desktop/CoursePaper/corpus/rossija/nesnyat/south/sochi/451404.xhtml\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for tree, class_text, open_name in read_txt('/Users/Valeriya/Desktop/CoursePaper/corpus'):\n",
    "    body = tree.xpath('//body')\n",
    "    text = '\\n'.join([elem.text for elem in body[0] if elem.text])\n",
    "#     if class_text != 'поздравление':\n",
    "#         class_text = 'другие'\n",
    "    if text:\n",
    "        texts.append((text, class_text, open_name))\n",
    "    else:\n",
    "        print(open_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4010"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = {}\n",
    "with open('formal_features_3.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        items = line.rstrip().split('\\t')\n",
    "        path = items[0]\n",
    "        feats = items[1::]\n",
    "        features[path] = feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classes = [text[1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4010"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "texts_2 = [text[0] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, (text, class_name, open_name) in enumerate(texts):\n",
    "    open_name = open_name.replace('/Users/Valeriya/Desktop/CoursePaper/', './')\n",
    "    formal_features = features[open_name][::]\n",
    "    n_excl = 0\n",
    "    for item in text[0]:\n",
    "        if item == '!':\n",
    "            n_excl+=1\n",
    "\n",
    "    n_ques = 0\n",
    "    for item in text[0]:\n",
    "        if item == '?':\n",
    "            n_ques+=1\n",
    "    formal_features.append(n_excl)\n",
    "    formal_features.append(n_ques)\n",
    "    \n",
    "    formal_features = [float(x) for x in formal_features]\n",
    "    formal_features = formal_features[:2:] + [x/formal_features[0] for x in formal_features[2::]]\n",
    "    \n",
    "    data.append(formal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_tf = TfidfVectorizer(ngram_range=(1,3))\n",
    "data_hash = vectorizer_tf.fit_transform(texts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "final = []\n",
    "for i, form_vec in enumerate(data):\n",
    "    sparse_form = scipy.sparse.csr_matrix(form_vec)\n",
    "    sparse_both = scipy.sparse.hstack([sparse_form, data_hash[i]])\n",
    "    final.append(sparse_both)\n",
    "\n",
    "data_sparse = scipy.sparse.vstack(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# vectorizer_tf = TfidfVectorizer(sublinear_tf=True, max_df=0.5, ngram_range=(1,3))\n",
    "# data_hash = vectorizer_tf.fit_transform(texts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i, j in zip(data, data_hash):\n",
    "#     final.append(i+list(j.toarray().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(final, classes, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_sparse, classes, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Метод tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# vectorizer_tf = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "# X_train_tf = vectorizer_tf.fit_transform(X_train)\n",
    "# X_test_tf = vectorizer_tf.transform(X_test)\n",
    "# print(\"Extracting best features by a chi-squared test\")\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=5000)\n",
    "X_train_ch = ch2.fit_transform(X_train, y_train)\n",
    "X_test_ch = ch2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Классификаторы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=350, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "accuracy:   0.753\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.74      0.32      0.45       254\n",
      "комментарий       0.86      0.52      0.65       204\n",
      "     статья       0.74      0.96      0.84       745\n",
      "\n",
      "avg / total       0.76      0.75      0.72      1203\n",
      "\n",
      "\n",
      "[[ 81  12 161]\n",
      " [  8 107  89]\n",
      " [ 21   6 718]]\n"
     ]
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "#     t0 = time()\n",
    "    if clf == MultinomialNB(alpha=.01):\n",
    "        clf.fit(X_train_ch, y_train)\n",
    "#         clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        clf.fit(X_train_ch, y_train)\n",
    "#         clf.fit(X_train_norm, y_train)\n",
    "\n",
    "\n",
    "#     t0 = time\n",
    "    if clf == MultinomialNB(alpha=.01):\n",
    "        pred = clf.predict(X_test_ch)\n",
    "#         pred = clf.predict(X_test)\n",
    "    else:\n",
    "        pred = clf.predict(X_test_ch)\n",
    "#         pred = clf.predict(X_test_norm)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    print()\n",
    "    \n",
    "    report = classification_report(y_test, pred)\n",
    "    print()\n",
    "    print(report)\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, pred)\n",
    "    print()\n",
    "    print(matrix)\n",
    "    \n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    if \"penalty\" in vars(clf):\n",
    "        return clf_descr+' '+str(clf.penalty), score\n",
    "    else:\n",
    "        return clf_descr, score\n",
    "\n",
    "results = []\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 350, bootstrap=False)\n",
    "results.append(benchmark(clf1))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:311: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.628\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.00      0.00      0.00       202\n",
      "     статья       0.63      1.00      0.77       755\n",
      "\n",
      "avg / total       0.39      0.63      0.48      1203\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.659\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.61      0.32      0.42       202\n",
      "     статья       0.66      0.97      0.79       755\n",
      "\n",
      "avg / total       0.52      0.66      0.56      1203\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.637\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.44      0.69      0.53       202\n",
      "     статья       0.71      0.83      0.77       755\n",
      "\n",
      "avg / total       0.52      0.64      0.57      1203\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.663\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.33      0.12      0.18       246\n",
      "комментарий       0.53      0.49      0.51       202\n",
      "     статья       0.72      0.88      0.79       755\n",
      "\n",
      "avg / total       0.61      0.66      0.62      1203\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "accuracy:   0.680\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.86      0.05      0.09       246\n",
      "комментарий       0.79      0.28      0.41       202\n",
      "     статья       0.67      0.99      0.80       755\n",
      "\n",
      "avg / total       0.73      0.68      0.59      1203\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/svm/classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.628\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.50      0.02      0.04       202\n",
      "     статья       0.63      1.00      0.77       755\n",
      "\n",
      "avg / total       0.48      0.63      0.49      1203\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.672\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.60      0.46      0.52       202\n",
      "     статья       0.68      0.95      0.79       755\n",
      "\n",
      "avg / total       0.53      0.67      0.59      1203\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/svm/classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.758\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.69      0.48      0.56       246\n",
      "комментарий       0.78      0.42      0.54       202\n",
      "     статья       0.77      0.94      0.85       755\n",
      "\n",
      "avg / total       0.75      0.76      0.74      1203\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "accuracy:   0.638\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.53      0.15      0.24       202\n",
      "     статья       0.64      0.98      0.78       755\n",
      "\n",
      "avg / total       0.49      0.64      0.53      1203\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.650\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.00      0.00      0.00       246\n",
      "комментарий       0.60      0.22      0.32       202\n",
      "     статья       0.65      0.98      0.78       755\n",
      "\n",
      "avg / total       0.51      0.65      0.55      1203\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.386\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.27      0.38      0.32       246\n",
      "комментарий       0.28      0.80      0.42       202\n",
      "     статья       0.73      0.28      0.40       755\n",
      "\n",
      "avg / total       0.56      0.39      0.39      1203\n",
      "\n",
      "================================================================================\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "accuracy:   0.684\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.91      0.08      0.15       246\n",
      "комментарий       0.74      0.28      0.40       202\n",
      "     статья       0.68      0.99      0.80       755\n",
      "\n",
      "avg / total       0.73      0.68      0.60      1203\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "accuracy:   0.656\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.49      0.09      0.15       246\n",
      "комментарий       0.59      0.16      0.26       202\n",
      "     статья       0.67      0.97      0.79       755\n",
      "\n",
      "avg / total       0.62      0.66      0.57      1203\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "accuracy:   0.218\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.49      0.24      0.32       246\n",
      "комментарий       0.19      0.99      0.31       202\n",
      "     статья       1.00      0.00      0.01       755\n",
      "\n",
      "avg / total       0.76      0.22      0.12      1203\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        prefit=False, thresho...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "accuracy:   0.185\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.68      0.09      0.15       246\n",
      "комментарий       0.17      1.00      0.29       202\n",
      "     статья       0.00      0.00      0.00       755\n",
      "\n",
      "avg / total       0.17      0.18      0.08      1203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-28353a2ca45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# clf_names, score = results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-28353a2ca45d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# clf_names, score = results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-28353a2ca45d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# clf_names, score = results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    report = classification_report(y_test, pred)\n",
    "    print()\n",
    "    print(report)\n",
    "    return clf_descr, score\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train Logistic Regression\n",
    "print('=' * 80)\n",
    "print(\"Logistic Regression\")\n",
    "results.append(benchmark(LogisticRegression()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC( penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "# clf_names, score = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
