{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Содержание:\n",
    "\n",
    "  \n",
    "    3) Метод Hashing с классификаторами:\n",
    "            1) Ridge Classifier\n",
    "            2) Perceptron\n",
    "            3) Passive Agressive\n",
    "            4) BeurnolliNB\n",
    "            5) MultinomialNB\n",
    "            6) KNeighbors\n",
    "            7) RandomForest\n",
    "            8) NearestCentroid\n",
    "            9) SGDClassifier\n",
    "            10) LinearSVC\n",
    "    4) Визуализация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Загружаю данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('./out.csv', 'r')\n",
    "file_hash_all = {}\n",
    "for line in f:\n",
    "    attrs = line.split(';')\n",
    "    path = attrs[0]\n",
    "    class_name = attrs[8]\n",
    "    if ' ' in class_name:\n",
    "        class_name = class_name.split()[0]\n",
    "    if '|' in class_name:\n",
    "        class_name = class_name.split('|')[0]\n",
    "    file_name = os.path.basename(path)\n",
    "    dir_name = os.path.dirname(path)\n",
    "    full_dir = os.path.join('/Users/Valeriya/Desktop/CoursePaper/corpus', dir_name)\n",
    "    files = os.listdir(full_dir)\n",
    "    if file_name in files:\n",
    "        file_hash_all[file_name] = class_name\n",
    "    elif file_name + '.xml' in files:\n",
    "        file_hash_all[file_name + '.xml'] = class_name\n",
    "    elif file_name + '.xhtml' in files:\n",
    "        file_hash_all[file_name + '.xhtml'] = class_name\n",
    "    else:\n",
    "        edit = 1000\n",
    "        true_name = ''\n",
    "        for file_in_dir in files:\n",
    "            dist = distance(file_name, file_in_dir)\n",
    "            if dist < edit:\n",
    "                edit = dist\n",
    "                true_name = file_in_dir\n",
    "        file_hash_all[true_name] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('./out.csv', 'r')\n",
    "# cl = {'отчет':0,'поздравление':0, 'интервью':0, 'репортаж':0, 'хроника':0, 'объявление':0, 'комментарий':0,\n",
    "#       'совет':0, 'анонс':0, 'заметка':0, 'информационное сообщение':0, 'статья':0}\n",
    "cl = {'статья':0, 'комментарий':0, 'интервью':0, 'объявление':0, 'поздравление':0}\n",
    "# cl = {'отчет':0,'поздравление':0}\n",
    "file_hash = defaultdict(int)\n",
    "file_all = defaultdict(int)\n",
    "for file_name, class_name in file_hash_all.items():\n",
    "    if class_name in cl:\n",
    "        cl[class_name] += 1\n",
    "#         if cl[class_name] <= 150:\n",
    "        file_hash[file_name] = class_name\n",
    "    file_all[class_name] +=1\n",
    "#     elif class_name == 'репортаж' or class_name == 'отчет':\n",
    "#         cl['other'] += 1\n",
    "#         file_hash[file_name] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "q = 0\n",
    "\n",
    "for i in file_all:\n",
    "    q+=1\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "for i in file_all:\n",
    "    t+= file_all[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'': 2575, 'указ': 7, 'репортаж': 331, 'доклад': 2, 'объявление': 384, 'заявление': 2, 'план': 1, 'совет': 121, 'биография': 9, 'комментарии': 173, 'аннотация': 15, 'инструкция': 17, 'рассказ': 3, 'резолюция': 1, 'календарь': 3, 'рецепт': 21, 'хроника': 284, 'интервью': 834, 'надпись': 8, 'буклет': 1, 'подбор': 1, 'памфлет': 2, 'поздравление': 198, 'гороскоп': 4, 'игра': 8, 'письмо': 94, 'type': 1, 'дневник,': 10, 'стихотворение': 21, 'подпись': 1, 'пресс-конференция': 1, 'обзор': 50, 'речь': 2, 'беседа': 8, 'закон': 5, 'публицистика': 7, 'лекция': 1, 'статья': 2503, 'консультация': 3, 'предисловие,': 2, 'монография': 1, 'отчет': 576, 'очерк': 108, 'анкета': 1, 'решение': 1, 'некролог': 17, 'заметка': 3715, 'положение': 8, 'рецензия': 90, 'пресс-релиз': 4, 'отзыв': 22, 'фельетон': 4, 'проповедь': 1, 'обращение': 29, 'комментарий': 674, 'предисловие': 2, 'постановление': 89, 'комикс': 6, 'тест': 3, 'правила': 3, 'информационное': 1034, 'анонс': 227, 'эссе': 14, 'послание': 1, 'миниатюра': 7, 'сказка': 1, 'распоряжение': 13, 'мемуары': 14, 'тезисы': 2, 'уведомление': 1, 'поучение': 1})\n"
     ]
    }
   ],
   "source": [
    "print(file_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            open_name = os.path.join(root, filename)\n",
    "            if filename in file_hash:\n",
    "                class_text = file_hash[filename]\n",
    "                tree = etree.parse(open_name)\n",
    "                yield tree, class_text, open_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def mystem_tokenizer(string):\n",
    "    tokens = m.lemmatize(string)\n",
    "    word_tokens = []\n",
    "    for token in tokens:\n",
    "        # if token.isalnum():\n",
    "        if token.isalpha():\n",
    "            word_tokens.append(token)\n",
    "    return word_tokens\n",
    "    \n",
    "# CountVectorizer(tokenizer=mystem_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/Desktop/CoursePaper/corpus/rossija/nesnyat/south/sochi/451404.xhtml\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for tree, class_text, open_name in read_txt('/Users/Valeriya/Desktop/CoursePaper/corpus'):\n",
    "    body = tree.xpath('//body')\n",
    "    text = '\\n'.join([elem.text for elem in body[0] if elem.text])\n",
    "#     if class_text != 'поздравление':\n",
    "#         class_text = 'другие'\n",
    "    if text:\n",
    "        texts.append((text, class_text, open_name))\n",
    "    else:\n",
    "        print(open_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = {}\n",
    "# with open('formal_features_3.tsv', 'r') as f:\n",
    "with open('formal_features_3.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        items = line.rstrip().split('\\t')\n",
    "        path = items[0]\n",
    "        feats = items[1::]\n",
    "        features[path] = feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classes = [text[1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4592"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "texts_2 = [text[0] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, (text, class_name, open_name) in enumerate(texts):\n",
    "    open_name = open_name.replace('/Users/Valeriya/Desktop/CoursePaper/', './')\n",
    "    formal_features = features[open_name][::]\n",
    "    n_excl = 0\n",
    "    for item in text[0]:\n",
    "        if item == '!':\n",
    "            n_excl+=1\n",
    "\n",
    "    n_ques = 0\n",
    "    for item in text[0]:\n",
    "        if item == '?':\n",
    "            n_ques+=1\n",
    "    formal_features.append(n_excl)\n",
    "    formal_features.append(n_ques)\n",
    "    \n",
    "    formal_features = [float(x) for x in formal_features]\n",
    "    formal_features = formal_features[:2:] + [x/formal_features[0] for x in formal_features[2::]]\n",
    "    \n",
    "    data.append(formal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = HashingVectorizer(non_negative=True, n_features=32)\n",
    "# X_train_hash = vectorizer.transform(X_train)\n",
    "# X_test_hash = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(non_negative=True, n_features=32)\n",
    "data_hash = vectorizer.fit_transform(texts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final = []\n",
    "for i, form_vec in enumerate(data):\n",
    "    sparse_form = scipy.sparse.csr_matrix(form_vec)\n",
    "    sparse_both = scipy.sparse.hstack([sparse_form, data[i]])\n",
    "    final.append(sparse_both)\n",
    "\n",
    "data_sparse = scipy.sparse.vstack(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# vectorizer_tf = TfidfVectorizer(sublinear_tf=True, max_df=0.5, ngram_range=(1,3))\n",
    "# vectorizer = HashingVectorizer(non_negative=True, n_features=32)\n",
    "\n",
    "# data_hash = vectorizer.fit_transform(data_sparse)\n",
    "# X_train_hash = vectorizer.transform(X_train)\n",
    "# X_test_hash = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i, j in zip(data, data_hash):\n",
    "#     final.append(i+list(j.toarray().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(final, classes, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_sparse, classes, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = HashingVectorizer(non_negative=True, n_features=32)\n",
    "# X_train_hash = vectorizer.fit_transform(X_train)\n",
    "# X_test_hash = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Метод tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# vectorizer_tf = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "# X_train_tf = vectorizer_tf.fit_transform(X_train)\n",
    "# X_test_tf = vectorizer_tf.transform(X_test)\n",
    "# print(\"Extracting best features by a chi-squared test\")\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=30)\n",
    "X_train_ch = ch2.fit_transform(X_train, y_train)\n",
    "X_test_ch = ch2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5da905d485e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Классификаторы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=350, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "accuracy:   0.753\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   интервью       0.74      0.32      0.45       254\n",
      "комментарий       0.86      0.52      0.65       204\n",
      "     статья       0.74      0.96      0.84       745\n",
      "\n",
      "avg / total       0.76      0.75      0.72      1203\n",
      "\n",
      "\n",
      "[[ 81  12 161]\n",
      " [  8 107  89]\n",
      " [ 21   6 718]]\n"
     ]
    }
   ],
   "source": [
    "# def benchmark(clf):\n",
    "#     print('_' * 80)\n",
    "#     print(\"Training: \")\n",
    "#     print(clf)\n",
    "# #     t0 = time()\n",
    "#     if clf == MultinomialNB(alpha=.01):\n",
    "#         clf.fit(X_train_ch, y_train)\n",
    "# #         clf.fit(X_train, y_train)\n",
    "#     else:\n",
    "#         clf.fit(X_train_ch, y_train)\n",
    "# #         clf.fit(X_train_norm, y_train)\n",
    "\n",
    "\n",
    "# #     t0 = time\n",
    "#     if clf == MultinomialNB(alpha=.01):\n",
    "#         pred = clf.predict(X_test_ch)\n",
    "# #         pred = clf.predict(X_test)\n",
    "#     else:\n",
    "#         pred = clf.predict(X_test_ch)\n",
    "# #         pred = clf.predict(X_test_norm)\n",
    "\n",
    "#     score = metrics.accuracy_score(y_test, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "#     print()\n",
    "    \n",
    "#     report = classification_report(y_test, pred)\n",
    "#     print()\n",
    "#     print(report)\n",
    "    \n",
    "#     matrix = confusion_matrix(y_test, pred)\n",
    "#     print()\n",
    "#     print(matrix)\n",
    "    \n",
    "#     clf_descr = str(clf).split('(')[0]\n",
    "#     if \"penalty\" in vars(clf):\n",
    "#         return clf_descr+' '+str(clf.penalty), score\n",
    "#     else:\n",
    "#         return clf_descr, score\n",
    "\n",
    "# results = []\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# clf1 = RandomForestClassifier(n_estimators = 350, bootstrap=False)\n",
    "# results.append(benchmark(clf1))\n",
    "\n",
    "# # make some plots\n",
    "\n",
    "# indices = np.arange(len(results))\n",
    "\n",
    "# results = [[x[i] for x in results] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:311: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.533\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.00      0.00      0.00       263\n",
      " комментарий       0.00      0.00      0.00       212\n",
      "  объявление       0.00      0.00      0.00       120\n",
      "поздравление       0.00      0.00      0.00        49\n",
      "      статья       0.53      1.00      0.70       734\n",
      "\n",
      " avg / total       0.28      0.53      0.37      1378\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.234\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.28      0.52      0.36       263\n",
      " комментарий       0.21      0.88      0.34       212\n",
      "  объявление       0.00      0.00      0.00       120\n",
      "поздравление       0.00      0.00      0.00        49\n",
      "      статья       0.00      0.00      0.00       734\n",
      "\n",
      " avg / total       0.09      0.23      0.12      1378\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.573\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.00      0.00      0.00       263\n",
      " комментарий       0.00      0.00      0.00       212\n",
      "  объявление       0.34      0.68      0.46       120\n",
      "поздравление       0.00      0.00      0.00        49\n",
      "      статья       0.62      0.97      0.76       734\n",
      "\n",
      " avg / total       0.36      0.57      0.44      1378\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.630\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.31      0.10      0.15       263\n",
      " комментарий       0.50      0.49      0.50       212\n",
      "  объявление       0.64      0.55      0.59       120\n",
      "поздравление       0.53      0.47      0.50        49\n",
      "      статья       0.69      0.89      0.77       734\n",
      "\n",
      " avg / total       0.58      0.63      0.59      1378\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "accuracy:   0.716\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.60      0.29      0.39       263\n",
      " комментарий       0.64      0.50      0.56       212\n",
      "  объявление       0.79      0.84      0.81       120\n",
      "поздравление       0.85      0.69      0.76        49\n",
      "      статья       0.73      0.91      0.81       734\n",
      "\n",
      " avg / total       0.70      0.72      0.69      1378\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/svm/classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.559\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.00      0.00      0.00       263\n",
      " комментарий       0.00      0.00      0.00       212\n",
      "  объявление       0.95      0.15      0.26       120\n",
      "поздравление       0.90      0.37      0.52        49\n",
      "      статья       0.55      1.00      0.71       734\n",
      "\n",
      " avg / total       0.41      0.56      0.42      1378\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.569\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.00      0.00      0.00       263\n",
      " комментарий       0.34      0.35      0.34       212\n",
      "  объявление       0.00      0.00      0.00       120\n",
      "поздравление       0.00      0.00      0.00        49\n",
      "      статья       0.61      0.97      0.75       734\n",
      "\n",
      " avg / total       0.38      0.57      0.45      1378\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/svm/classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.678\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.58      0.32      0.41       263\n",
      " комментарий       0.64      0.17      0.27       212\n",
      "  объявление       0.79      0.74      0.76       120\n",
      "поздравление       0.82      0.73      0.77        49\n",
      "      статья       0.68      0.94      0.79       734\n",
      "\n",
      " avg / total       0.67      0.68      0.63      1378\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "accuracy:   0.553\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.00      0.00      0.00       263\n",
      " комментарий       0.26      0.23      0.25       212\n",
      "  объявление       0.00      0.00      0.00       120\n",
      "поздравление       0.00      0.00      0.00        49\n",
      "      статья       0.60      0.97      0.74       734\n",
      "\n",
      " avg / total       0.36      0.55      0.43      1378\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.536\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.00      0.00      0.00       263\n",
      " комментарий       0.00      0.00      0.00       212\n",
      "  объявление       0.00      0.00      0.00       120\n",
      "поздравление       0.14      0.88      0.25        49\n",
      "      статья       0.65      0.95      0.77       734\n",
      "\n",
      " avg / total       0.35      0.54      0.42      1378\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "accuracy:   0.310\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.30      0.46      0.36       263\n",
      " комментарий       0.18      0.38      0.25       212\n",
      "  объявление       0.16      0.16      0.16       120\n",
      "поздравление       0.22      0.82      0.35        49\n",
      "      статья       0.69      0.23      0.34       734\n",
      "\n",
      " avg / total       0.47      0.31      0.32      1378\n",
      "\n",
      "================================================================================\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Valeriya/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.623\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.56      0.02      0.04       263\n",
      " комментарий       0.57      0.06      0.10       212\n",
      "  объявление       0.81      0.68      0.74       120\n",
      "поздравление       0.89      0.67      0.77        49\n",
      "      статья       0.60      0.99      0.75       734\n",
      "\n",
      " avg / total       0.62      0.62      0.51      1378\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "accuracy:   0.442\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.35      0.37      0.35       263\n",
      " комментарий       0.22      0.29      0.25       212\n",
      "  объявление       0.30      0.28      0.29       120\n",
      "поздравление       0.22      0.82      0.35        49\n",
      "      статья       0.71      0.51      0.60       734\n",
      "\n",
      " avg / total       0.51      0.44      0.46      1378\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "accuracy:   0.581\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.31      0.19      0.24       263\n",
      " комментарий       0.37      0.48      0.41       212\n",
      "  объявление       0.67      0.70      0.69       120\n",
      "поздравление       0.56      0.73      0.64        49\n",
      "      статья       0.70      0.72      0.71       734\n",
      "\n",
      " avg / total       0.57      0.58      0.57      1378\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        prefit=False, thresho...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "accuracy:   0.318\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    интервью       0.22      0.02      0.03       263\n",
      " комментарий       0.14      0.51      0.22       212\n",
      "  объявление       0.63      0.75      0.69       120\n",
      "поздравление       0.27      0.76      0.39        49\n",
      "      статья       0.65      0.27      0.38       734\n",
      "\n",
      " avg / total       0.47      0.32      0.32      1378\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-28353a2ca45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# clf_names, score = results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-28353a2ca45d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# clf_names, score = results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-28353a2ca45d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# clf_names, score = results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    report = classification_report(y_test, pred)\n",
    "    print()\n",
    "    print(report)\n",
    "    return clf_descr, score\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train Logistic Regression\n",
    "print('=' * 80)\n",
    "print(\"Logistic Regression\")\n",
    "results.append(benchmark(LogisticRegression()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC( penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "# clf_names, score = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
